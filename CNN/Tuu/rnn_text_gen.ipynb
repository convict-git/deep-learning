{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "hOlHlOmOqyxg",
    "outputId": "c3ace680-e32f-456b-e1d0-68830f83e15d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "omDoJpxnqaBv"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "colab_type": "code",
    "id": "iO7Hnzm9qaCC",
    "outputId": "caa0a5c0-019e-400c-a06c-17628ae9ddff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHAPTER I. Down the Rabbit-Hole\n",
      "\n",
      "Alice was beginning to get very tired of sitting by her sister on t\n"
     ]
    }
   ],
   "source": [
    "filename = \"/content/drive/My Drive/Alice2.txt\"\n",
    "raw_text = open(filename).read()\n",
    "print(raw_text[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "exGlwgehtmKp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aPtwN1peqaCU"
   },
   "outputs": [],
   "source": [
    "# create mapping of unique words to integers, and reverse\n",
    "raw_text_words=re.findall(r\"[\\w]+|[.!?;]\", raw_text)\n",
    "#raw_text_words = raw_text.split()\n",
    "#print(raw_text_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iZfl_JGqaCe"
   },
   "outputs": [],
   "source": [
    "words = sorted(list(set(raw_text_words)))\n",
    "#word to integer mapping\n",
    "word_to_int = dict((w, i) for i, w in enumerate(words))\n",
    "#integer to word mapping\n",
    "int_to_word = dict((i, w) for i, w in enumerate(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1zHZnFEYqaCo"
   },
   "outputs": [],
   "source": [
    "#print(word_to_int)\n",
    "#print(int_to_word)\n",
    "#print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "4ugH6A9rqaC8",
    "outputId": "f4948dde-c389-400b-e583-14d1e6a55670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Words in the document:  4614\n",
      "Total Vocab:  1013\n"
     ]
    }
   ],
   "source": [
    "n_words = len(raw_text_words)\n",
    "n_vocab = len(words)\n",
    "print(\"Total Words in the document: \", n_words)\n",
    "print(\"Total Vocab: \", n_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ti6aouMEqaDF"
   },
   "outputs": [],
   "source": [
    "# prepare the dataset of input to output pairs encoded as integers\n",
    "seq_length = 30\n",
    "dataX = []\n",
    "dataY = []\n",
    "for i in range(0, n_words - seq_length, 1):\n",
    "    seq_in = raw_text_words[i:i + seq_length]\n",
    "    seq_out = raw_text_words[i + seq_length]\n",
    "    dataX.append([word_to_int[word] for word in seq_in])\n",
    "    dataY.append(word_to_int[seq_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "MuT5gV1SqaDM",
    "outputId": "f39dc449-9879-4738-bbd8-31432df4f9fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[18,\n",
       "  55,\n",
       "  1,\n",
       "  30,\n",
       "  883,\n",
       "  101,\n",
       "  52,\n",
       "  9,\n",
       "  961,\n",
       "  204,\n",
       "  910,\n",
       "  430,\n",
       "  948,\n",
       "  909,\n",
       "  644,\n",
       "  806,\n",
       "  232,\n",
       "  475,\n",
       "  803,\n",
       "  648,\n",
       "  883,\n",
       "  190,\n",
       "  169,\n",
       "  644,\n",
       "  466,\n",
       "  636,\n",
       "  910,\n",
       "  324,\n",
       "  649,\n",
       "  656],\n",
       " [55,\n",
       "  1,\n",
       "  30,\n",
       "  883,\n",
       "  101,\n",
       "  52,\n",
       "  9,\n",
       "  961,\n",
       "  204,\n",
       "  910,\n",
       "  430,\n",
       "  948,\n",
       "  909,\n",
       "  644,\n",
       "  806,\n",
       "  232,\n",
       "  475,\n",
       "  803,\n",
       "  648,\n",
       "  883,\n",
       "  190,\n",
       "  169,\n",
       "  644,\n",
       "  466,\n",
       "  636,\n",
       "  910,\n",
       "  324,\n",
       "  649,\n",
       "  656,\n",
       "  932],\n",
       " [1,\n",
       "  30,\n",
       "  883,\n",
       "  101,\n",
       "  52,\n",
       "  9,\n",
       "  961,\n",
       "  204,\n",
       "  910,\n",
       "  430,\n",
       "  948,\n",
       "  909,\n",
       "  644,\n",
       "  806,\n",
       "  232,\n",
       "  475,\n",
       "  803,\n",
       "  648,\n",
       "  883,\n",
       "  190,\n",
       "  169,\n",
       "  644,\n",
       "  466,\n",
       "  636,\n",
       "  910,\n",
       "  324,\n",
       "  649,\n",
       "  656,\n",
       "  932,\n",
       "  782],\n",
       " [30,\n",
       "  883,\n",
       "  101,\n",
       "  52,\n",
       "  9,\n",
       "  961,\n",
       "  204,\n",
       "  910,\n",
       "  430,\n",
       "  948,\n",
       "  909,\n",
       "  644,\n",
       "  806,\n",
       "  232,\n",
       "  475,\n",
       "  803,\n",
       "  648,\n",
       "  883,\n",
       "  190,\n",
       "  169,\n",
       "  644,\n",
       "  466,\n",
       "  636,\n",
       "  910,\n",
       "  324,\n",
       "  649,\n",
       "  656,\n",
       "  932,\n",
       "  782,\n",
       "  449],\n",
       " [883,\n",
       "  101,\n",
       "  52,\n",
       "  9,\n",
       "  961,\n",
       "  204,\n",
       "  910,\n",
       "  430,\n",
       "  948,\n",
       "  909,\n",
       "  644,\n",
       "  806,\n",
       "  232,\n",
       "  475,\n",
       "  803,\n",
       "  648,\n",
       "  883,\n",
       "  190,\n",
       "  169,\n",
       "  644,\n",
       "  466,\n",
       "  636,\n",
       "  910,\n",
       "  324,\n",
       "  649,\n",
       "  656,\n",
       "  932,\n",
       "  782,\n",
       "  449,\n",
       "  676]]"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "tipGgqnxqaDX",
    "outputId": "d72fd0a7-5ed7-435e-d2c7-0ca3c2dcae7e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[932, 782, 449, 676, 511]"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataY[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pi40gjLBqaDg"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "n0O-8efTqaDq",
    "outputId": "c9ccfe05-4e32-4a31-8d7d-9920cee7797b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eTFKyra6qaD3",
    "outputId": "098b7400-1c40-46a2-ffc7-3f95818ae292"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Down'"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_to_word[30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8WOHgKneqaD_",
    "outputId": "991316e3-34cf-4f46-d064-157230f92982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns:  4584\n"
     ]
    }
   ],
   "source": [
    "n_patterns = len(dataX)\n",
    "print(\"Total Patterns: \", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NGrLhSLHqaEG"
   },
   "outputs": [],
   "source": [
    "# reshape X to be [samples, time steps, features]\n",
    "x_train = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
    "# normalize\n",
    "x_train = x_train / float(n_vocab)\n",
    "# one hot encode the output variable\n",
    "y_train = np.eye(n_vocab)[dataY]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "XvFx_9-VqaEN",
    "outputId": "0e96cd2a-2865-4c14-e676-478d78fa50db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.017769  ]\n",
      "  [0.05429418]\n",
      "  [0.00098717]\n",
      "  [0.029615  ]\n",
      "  [0.87166831]\n",
      "  [0.09970385]\n",
      "  [0.05133268]\n",
      "  [0.0088845 ]\n",
      "  [0.94866732]\n",
      "  [0.20138203]\n",
      "  [0.89832182]\n",
      "  [0.42448174]\n",
      "  [0.93583416]\n",
      "  [0.89733465]\n",
      "  [0.63573544]\n",
      "  [0.79565647]\n",
      "  [0.2290227 ]\n",
      "  [0.46890424]\n",
      "  [0.79269497]\n",
      "  [0.63968411]\n",
      "  [0.87166831]\n",
      "  [0.1875617 ]\n",
      "  [0.16683119]\n",
      "  [0.63573544]\n",
      "  [0.46001974]\n",
      "  [0.6278381 ]\n",
      "  [0.89832182]\n",
      "  [0.31984205]\n",
      "  [0.64067127]\n",
      "  [0.64758144]]\n",
      "\n",
      " [[0.05429418]\n",
      "  [0.00098717]\n",
      "  [0.029615  ]\n",
      "  [0.87166831]\n",
      "  [0.09970385]\n",
      "  [0.05133268]\n",
      "  [0.0088845 ]\n",
      "  [0.94866732]\n",
      "  [0.20138203]\n",
      "  [0.89832182]\n",
      "  [0.42448174]\n",
      "  [0.93583416]\n",
      "  [0.89733465]\n",
      "  [0.63573544]\n",
      "  [0.79565647]\n",
      "  [0.2290227 ]\n",
      "  [0.46890424]\n",
      "  [0.79269497]\n",
      "  [0.63968411]\n",
      "  [0.87166831]\n",
      "  [0.1875617 ]\n",
      "  [0.16683119]\n",
      "  [0.63573544]\n",
      "  [0.46001974]\n",
      "  [0.6278381 ]\n",
      "  [0.89832182]\n",
      "  [0.31984205]\n",
      "  [0.64067127]\n",
      "  [0.64758144]\n",
      "  [0.92003949]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wzAGceLgqaEU",
    "outputId": "7961a3eb-81ab-4f5d-a11d-629bccb37fab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(y_train[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "aVe4WEUdqaEc",
    "outputId": "185a0a70-12e2-4d28-970f-44cecf81dac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4584, 30, 1)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wkV_ULeGqaEo",
    "outputId": "1ce3f960-2e23-4c96-bca0-7131decc238c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4584, 1013)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7mjV4RFzqaEw"
   },
   "outputs": [],
   "source": [
    "batch_size = y_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "colab_type": "code",
    "id": "b3rO0uBVqaE5",
    "outputId": "3884c463-3329-4d78-ba30-e04889b38429"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-dd305903709f>:8: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-20-dd305903709f>:10: MultiRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.StackedRNNCells, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From <ipython-input-20-dd305903709f>:11: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1478567c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1478567c18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1478567c18>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method MultiRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.MultiRNNCell object at 0x7f1478567c18>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/rnn_cell_impl.py:459: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567978>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567a20>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BasicRNNCell.call of <tensorflow.python.ops.rnn_cell_impl.BasicRNNCell object at 0x7f1478567a20>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING:tensorflow:From <ipython-input-20-dd305903709f>:12: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1478567b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1478567b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n",
      "WARNING: Entity <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1478567b38>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method Dense.call of <tensorflow.python.layers.core.Dense object at 0x7f1478567b38>>: AssertionError: Bad argument number for Name: 3, expecting 4\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "X = tf.placeholder(tf.float32,  shape=(None, seq_length, 1))\n",
    "Y = tf.placeholder(tf.float32,  shape=(None, n_vocab))\n",
    "num_layers = 2   \n",
    "hidden_units=200\n",
    "#rnn_cell = tf.nn.rnn_cell.BasicRNNCell(num_units=hidden_units, activation=tf.nn.tanh)\n",
    "layers = [tf.nn.rnn_cell.BasicRNNCell(num_units=hidden_units, activation=tf.nn.tanh)\n",
    "        for _ in range(num_layers)]\n",
    "\n",
    "cells = tf.nn.rnn_cell.MultiRNNCell(layers)\n",
    "outputs, state = tf.nn.dynamic_rnn(cells,X,dtype=tf.float32)\n",
    "logits = tf.layers.dense(outputs[:,-1], n_vocab)\n",
    "prob = tf.nn.softmax(logits)\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "                             logits=logits, labels=Y))\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss)\n",
    "acc = tf.reduce_mean(tf.cast(\n",
    "                        tf.equal(\n",
    "                            tf.argmax(logits, 1),\n",
    "                            tf.argmax(Y, 1),\n",
    "                        ),\n",
    "                        tf.float32,\n",
    "                    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "7kjP93dSqaE_",
    "outputId": "d12fa802-469c-4d31-c41c-9d36db19e55c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 6.160534  Accuracy: 0.0\n",
      "loss: 5.9500813  Accuracy: 0.023809524\n",
      "loss: 5.8374324  Accuracy: 0.023809524\n",
      "loss: 5.9182034  Accuracy: 0.023809524\n",
      "loss: 5.9054966  Accuracy: 0.023809524\n",
      "loss: 5.862303  Accuracy: 0.0\n",
      "loss: 5.9160943  Accuracy: 0.023809524\n",
      "loss: 5.907993  Accuracy: 0.023809524\n",
      "loss: 5.9709463  Accuracy: 0.023809524\n",
      "loss: 5.89994  Accuracy: 0.023809524\n",
      "loss: 5.8996024  Accuracy: 0.0\n",
      "loss: 5.9085293  Accuracy: 0.071428575\n",
      "loss: 5.899474  Accuracy: 0.071428575\n",
      "loss: 5.9509544  Accuracy: 0.023809524\n",
      "loss: 5.869161  Accuracy: 0.071428575\n",
      "loss: 5.81982  Accuracy: 0.0\n",
      "loss: 5.8561206  Accuracy: 0.0952381\n",
      "loss: 5.917156  Accuracy: 0.023809524\n",
      "loss: 5.900964  Accuracy: 0.023809524\n",
      "loss: 5.921371  Accuracy: 0.023809524\n",
      "loss: 5.909421  Accuracy: 0.023809524\n",
      "loss: 5.8936467  Accuracy: 0.023809524\n",
      "loss: 5.9338903  Accuracy: 0.023809524\n",
      "loss: 5.89992  Accuracy: 0.023809524\n",
      "loss: 5.877086  Accuracy: 0.071428575\n",
      "loss: 5.868913  Accuracy: 0.023809524\n",
      "loss: 5.8927636  Accuracy: 0.023809524\n",
      "loss: 5.8951926  Accuracy: 0.023809524\n",
      "loss: 5.8542504  Accuracy: 0.023809524\n",
      "loss: 5.903367  Accuracy: 0.023809524\n",
      "loss: 5.8895593  Accuracy: 0.023809524\n",
      "loss: 5.88445  Accuracy: 0.023809524\n",
      "loss: 5.8531227  Accuracy: 0.071428575\n",
      "loss: 5.9184656  Accuracy: 0.071428575\n",
      "loss: 5.8652334  Accuracy: 0.023809524\n",
      "loss: 5.8922076  Accuracy: 0.023809524\n",
      "loss: 5.8623056  Accuracy: 0.023809524\n",
      "loss: 5.8878593  Accuracy: 0.023809524\n",
      "loss: 5.830364  Accuracy: 0.05952381\n",
      "loss: 5.9088492  Accuracy: 0.035714287\n",
      "loss: 5.8801246  Accuracy: 0.0952381\n",
      "loss: 5.8884583  Accuracy: 0.071428575\n",
      "loss: 5.854273  Accuracy: 0.04761905\n",
      "loss: 5.886373  Accuracy: 0.023809524\n",
      "loss: 5.847169  Accuracy: 0.071428575\n",
      "loss: 5.8295126  Accuracy: 0.11904762\n",
      "loss: 5.839318  Accuracy: 0.05952381\n",
      "loss: 5.83586  Accuracy: 0.035714287\n",
      "loss: 5.8504763  Accuracy: 0.023809524\n",
      "loss: 5.745956  Accuracy: 0.071428575\n",
      "loss: 5.761795  Accuracy: 0.04761905\n",
      "loss: 5.710876  Accuracy: 0.05952381\n",
      "loss: 5.653777  Accuracy: 0.04761905\n",
      "loss: 5.6365075  Accuracy: 0.035714287\n",
      "loss: 5.5330515  Accuracy: 0.035714287\n",
      "loss: 5.4873605  Accuracy: 0.083333336\n",
      "loss: 5.4600883  Accuracy: 0.04761905\n",
      "loss: 5.4432364  Accuracy: 0.083333336\n",
      "loss: 5.4137483  Accuracy: 0.05952381\n",
      "loss: 5.4020653  Accuracy: 0.071428575\n",
      "loss: 5.3884277  Accuracy: 0.035714287\n",
      "loss: 5.270573  Accuracy: 0.05952381\n",
      "loss: 5.2970667  Accuracy: 0.05952381\n",
      "loss: 5.197334  Accuracy: 0.035714287\n",
      "loss: 5.246254  Accuracy: 0.04761905\n",
      "loss: 5.1547723  Accuracy: 0.023809524\n",
      "loss: 5.1675153  Accuracy: 0.035714287\n",
      "loss: 5.1345434  Accuracy: 0.04761905\n",
      "loss: 5.11467  Accuracy: 0.04761905\n",
      "loss: 5.0064254  Accuracy: 0.04761905\n",
      "loss: 5.045054  Accuracy: 0.071428575\n",
      "loss: 5.0403557  Accuracy: 0.083333336\n",
      "loss: 4.9666424  Accuracy: 0.10714286\n",
      "loss: 4.8660364  Accuracy: 0.05952381\n",
      "loss: 5.068032  Accuracy: 0.10714286\n",
      "loss: 4.758133  Accuracy: 0.083333336\n",
      "loss: 4.978058  Accuracy: 0.071428575\n",
      "loss: 4.9954185  Accuracy: 0.04761905\n",
      "loss: 4.8676934  Accuracy: 0.083333336\n",
      "loss: 4.661868  Accuracy: 0.083333336\n",
      "loss: 5.0028944  Accuracy: 0.083333336\n",
      "loss: 4.878235  Accuracy: 0.083333336\n",
      "loss: 4.760732  Accuracy: 0.071428575\n",
      "loss: 4.6363006  Accuracy: 0.083333336\n",
      "loss: 4.4602246  Accuracy: 0.14285715\n",
      "loss: 4.426415  Accuracy: 0.15476191\n",
      "loss: 4.3124547  Accuracy: 0.16666667\n",
      "loss: 4.3607802  Accuracy: 0.15476191\n",
      "loss: 4.204936  Accuracy: 0.14285715\n",
      "loss: 4.2175136  Accuracy: 0.13095239\n",
      "loss: 4.8836203  Accuracy: 0.023809524\n",
      "loss: 4.5889306  Accuracy: 0.083333336\n",
      "loss: 4.509907  Accuracy: 0.11904762\n",
      "loss: 4.395762  Accuracy: 0.17857143\n",
      "loss: 4.623348  Accuracy: 0.083333336\n",
      "loss: 4.298043  Accuracy: 0.13095239\n",
      "loss: 4.315496  Accuracy: 0.13095239\n",
      "loss: 4.3842664  Accuracy: 0.083333336\n",
      "loss: 4.43254  Accuracy: 0.0952381\n",
      "loss: 4.3727703  Accuracy: 0.11904762\n",
      "loss: 4.189234  Accuracy: 0.13095239\n",
      "loss: 4.0855436  Accuracy: 0.21428572\n",
      "loss: 4.1806064  Accuracy: 0.15476191\n",
      "loss: 4.2510047  Accuracy: 0.14285715\n",
      "loss: 4.0784693  Accuracy: 0.17857143\n",
      "loss: 3.968859  Accuracy: 0.16666667\n",
      "loss: 3.8502507  Accuracy: 0.23809524\n",
      "loss: 3.9634156  Accuracy: 0.21428572\n",
      "loss: 4.509495  Accuracy: 0.05952381\n",
      "loss: 4.3132663  Accuracy: 0.13095239\n",
      "loss: 4.237031  Accuracy: 0.10714286\n",
      "loss: 3.9298615  Accuracy: 0.21428572\n",
      "loss: 4.486589  Accuracy: 0.035714287\n",
      "loss: 4.270304  Accuracy: 0.17857143\n",
      "loss: 3.8317225  Accuracy: 0.20238096\n",
      "loss: 3.8914046  Accuracy: 0.21428572\n",
      "loss: 3.9743176  Accuracy: 0.1904762\n",
      "loss: 3.9203625  Accuracy: 0.25\n",
      "loss: 3.9807925  Accuracy: 0.25\n",
      "loss: 3.9042423  Accuracy: 0.17857143\n",
      "loss: 3.7471285  Accuracy: 0.25\n",
      "loss: 3.6506293  Accuracy: 0.21428572\n",
      "loss: 3.7877011  Accuracy: 0.21428572\n",
      "loss: 4.0797954  Accuracy: 0.16666667\n",
      "loss: 3.8280058  Accuracy: 0.23809524\n",
      "loss: 3.6711032  Accuracy: 0.22619048\n",
      "loss: 3.7876956  Accuracy: 0.1904762\n",
      "loss: 4.099725  Accuracy: 0.14285715\n",
      "loss: 4.0937634  Accuracy: 0.21428572\n",
      "loss: 4.064379  Accuracy: 0.14285715\n",
      "loss: 4.150509  Accuracy: 0.21428572\n",
      "loss: 3.916748  Accuracy: 0.1904762\n",
      "loss: 4.1532845  Accuracy: 0.14285715\n",
      "loss: 3.6781852  Accuracy: 0.20238096\n",
      "loss: 3.9415243  Accuracy: 0.1904762\n",
      "loss: 3.4020092  Accuracy: 0.2857143\n",
      "loss: 3.727878  Accuracy: 0.15476191\n",
      "loss: 3.3417587  Accuracy: 0.3452381\n",
      "loss: 3.5856261  Accuracy: 0.26190478\n",
      "loss: 3.5142124  Accuracy: 0.27380952\n",
      "loss: 3.4550636  Accuracy: 0.29761904\n",
      "loss: 3.2403102  Accuracy: 0.3690476\n",
      "loss: 3.1472244  Accuracy: 0.30952382\n",
      "loss: 3.145637  Accuracy: 0.2857143\n",
      "loss: 3.0627046  Accuracy: 0.3452381\n",
      "loss: 3.0327225  Accuracy: 0.3690476\n",
      "loss: 2.885699  Accuracy: 0.33333334\n",
      "loss: 2.9878433  Accuracy: 0.33333334\n",
      "loss: 2.85883  Accuracy: 0.39285713\n",
      "loss: 2.8392565  Accuracy: 0.3452381\n",
      "loss: 2.886861  Accuracy: 0.3809524\n",
      "loss: 2.9631574  Accuracy: 0.4047619\n",
      "loss: 3.0653546  Accuracy: 0.3690476\n",
      "loss: 2.9022307  Accuracy: 0.3809524\n",
      "loss: 2.8560686  Accuracy: 0.4047619\n",
      "loss: 2.7711377  Accuracy: 0.4047619\n",
      "loss: 2.6922746  Accuracy: 0.41666666\n",
      "loss: 2.6411052  Accuracy: 0.45238096\n",
      "loss: 2.5969448  Accuracy: 0.4642857\n",
      "loss: 2.5728154  Accuracy: 0.44047618\n",
      "loss: 2.5284333  Accuracy: 0.41666666\n",
      "loss: 2.460766  Accuracy: 0.41666666\n",
      "loss: 2.3873537  Accuracy: 0.4642857\n",
      "loss: 2.3532474  Accuracy: 0.44047618\n",
      "loss: 2.273675  Accuracy: 0.52380955\n",
      "loss: 2.2612066  Accuracy: 0.47619048\n",
      "loss: 2.2123938  Accuracy: 0.53571427\n",
      "loss: 2.1970494  Accuracy: 0.5\n",
      "loss: 2.1561072  Accuracy: 0.54761904\n",
      "loss: 2.1219976  Accuracy: 0.52380955\n",
      "loss: 2.1991162  Accuracy: 0.5\n",
      "loss: 2.0684185  Accuracy: 0.53571427\n",
      "loss: 2.0122647  Accuracy: 0.53571427\n",
      "loss: 1.947732  Accuracy: 0.61904764\n",
      "loss: 1.995258  Accuracy: 0.5952381\n",
      "loss: 1.9319767  Accuracy: 0.61904764\n",
      "loss: 1.913347  Accuracy: 0.63095236\n",
      "loss: 1.8714826  Accuracy: 0.64285713\n",
      "loss: 1.8503907  Accuracy: 0.63095236\n",
      "loss: 1.9031553  Accuracy: 0.64285713\n",
      "loss: 1.8956728  Accuracy: 0.5833333\n",
      "loss: 1.8870648  Accuracy: 0.64285713\n",
      "loss: 1.7860273  Accuracy: 0.61904764\n",
      "loss: 1.7044474  Accuracy: 0.6904762\n",
      "loss: 1.7589015  Accuracy: 0.70238096\n",
      "loss: 1.6731282  Accuracy: 0.71428573\n",
      "loss: 1.6470726  Accuracy: 0.6785714\n",
      "loss: 1.5739728  Accuracy: 0.78571427\n",
      "loss: 1.5296565  Accuracy: 0.78571427\n",
      "loss: 1.5803454  Accuracy: 0.7380952\n",
      "loss: 1.6120242  Accuracy: 0.6904762\n",
      "loss: 1.5841169  Accuracy: 0.71428573\n",
      "loss: 1.4713558  Accuracy: 0.8214286\n",
      "loss: 1.4818289  Accuracy: 0.7619048\n",
      "loss: 1.5209234  Accuracy: 0.7619048\n",
      "loss: 1.482599  Accuracy: 0.78571427\n",
      "loss: 1.5734644  Accuracy: 0.70238096\n",
      "loss: 1.4482634  Accuracy: 0.77380955\n",
      "loss: 1.6663575  Accuracy: 0.64285713\n",
      "loss: 1.5380278  Accuracy: 0.6666667\n",
      "loss: 1.437448  Accuracy: 0.77380955\n",
      "loss: 1.4267952  Accuracy: 0.75\n",
      "loss: 1.4235798  Accuracy: 0.8214286\n",
      "loss: 1.3728844  Accuracy: 0.77380955\n",
      "loss: 1.4012337  Accuracy: 0.77380955\n",
      "loss: 1.4569281  Accuracy: 0.77380955\n",
      "loss: 1.4165298  Accuracy: 0.6785714\n",
      "loss: 1.5189456  Accuracy: 0.70238096\n",
      "loss: 1.5638868  Accuracy: 0.6904762\n",
      "loss: 1.4846537  Accuracy: 0.7380952\n",
      "loss: 1.4632742  Accuracy: 0.7380952\n",
      "loss: 1.3802857  Accuracy: 0.7619048\n",
      "loss: 1.4757116  Accuracy: 0.63095236\n",
      "loss: 1.3173033  Accuracy: 0.78571427\n",
      "loss: 1.312018  Accuracy: 0.78571427\n",
      "loss: 1.4026802  Accuracy: 0.72619045\n",
      "loss: 1.4060271  Accuracy: 0.7380952\n",
      "loss: 1.3870951  Accuracy: 0.75\n",
      "loss: 1.4325556  Accuracy: 0.7619048\n",
      "loss: 1.3954593  Accuracy: 0.7380952\n",
      "loss: 1.266744  Accuracy: 0.78571427\n",
      "loss: 1.5028712  Accuracy: 0.6785714\n",
      "loss: 1.3574121  Accuracy: 0.70238096\n",
      "loss: 1.3786314  Accuracy: 0.72619045\n",
      "loss: 1.3757845  Accuracy: 0.72619045\n",
      "loss: 1.4024264  Accuracy: 0.70238096\n",
      "loss: 1.3451382  Accuracy: 0.72619045\n",
      "loss: 1.3656816  Accuracy: 0.70238096\n",
      "loss: 1.4080527  Accuracy: 0.72619045\n",
      "loss: 1.2231104  Accuracy: 0.77380955\n",
      "loss: 1.3957435  Accuracy: 0.71428573\n",
      "loss: 1.6127783  Accuracy: 0.61904764\n",
      "loss: 1.3410957  Accuracy: 0.75\n",
      "loss: 1.3374189  Accuracy: 0.70238096\n",
      "loss: 1.1648378  Accuracy: 0.8214286\n",
      "loss: 1.4492143  Accuracy: 0.70238096\n",
      "loss: 1.2071584  Accuracy: 0.7619048\n",
      "loss: 1.3801329  Accuracy: 0.7380952\n",
      "loss: 1.1907624  Accuracy: 0.75\n",
      "loss: 1.326459  Accuracy: 0.77380955\n",
      "loss: 1.102508  Accuracy: 0.78571427\n",
      "loss: 1.4267077  Accuracy: 0.6904762\n",
      "loss: 1.1284353  Accuracy: 0.78571427\n",
      "loss: 1.1563118  Accuracy: 0.77380955\n",
      "loss: 1.134746  Accuracy: 0.8095238\n",
      "loss: 1.4165705  Accuracy: 0.6785714\n",
      "loss: 1.2153547  Accuracy: 0.7380952\n",
      "loss: 1.2313436  Accuracy: 0.7380952\n",
      "loss: 1.2800692  Accuracy: 0.75\n",
      "loss: 1.3511887  Accuracy: 0.70238096\n",
      "loss: 1.0669824  Accuracy: 0.79761904\n",
      "loss: 1.2710435  Accuracy: 0.7380952\n",
      "loss: 1.1944628  Accuracy: 0.77380955\n",
      "loss: 1.1340439  Accuracy: 0.78571427\n",
      "loss: 1.0162051  Accuracy: 0.8095238\n",
      "loss: 1.2306802  Accuracy: 0.72619045\n",
      "loss: 0.9618482  Accuracy: 0.8452381\n",
      "loss: 0.95466757  Accuracy: 0.8095238\n",
      "loss: 0.9894834  Accuracy: 0.8095238\n",
      "loss: 0.85251456  Accuracy: 0.89285713\n",
      "loss: 0.9085284  Accuracy: 0.8452381\n",
      "loss: 0.82175136  Accuracy: 0.88095236\n",
      "loss: 0.9839693  Accuracy: 0.8452381\n",
      "loss: 0.87074023  Accuracy: 0.85714287\n",
      "loss: 0.7745188  Accuracy: 0.85714287\n",
      "loss: 0.7677447  Accuracy: 0.9047619\n",
      "loss: 0.86182123  Accuracy: 0.86904764\n",
      "loss: 0.7586648  Accuracy: 0.9047619\n",
      "loss: 0.7352439  Accuracy: 0.88095236\n",
      "loss: 0.7242138  Accuracy: 0.88095236\n",
      "loss: 0.73419607  Accuracy: 0.9166667\n",
      "loss: 0.76208967  Accuracy: 0.8452381\n",
      "loss: 0.7374332  Accuracy: 0.9047619\n",
      "loss: 0.7598352  Accuracy: 0.88095236\n",
      "loss: 0.81304157  Accuracy: 0.88095236\n",
      "loss: 0.74658346  Accuracy: 0.9166667\n",
      "loss: 0.8945299  Accuracy: 0.8214286\n",
      "loss: 0.81453484  Accuracy: 0.8214286\n",
      "loss: 0.7621625  Accuracy: 0.86904764\n",
      "loss: 0.9194348  Accuracy: 0.8095238\n",
      "loss: 0.79400635  Accuracy: 0.8452381\n",
      "loss: 0.850212  Accuracy: 0.8214286\n",
      "loss: 0.8422742  Accuracy: 0.79761904\n",
      "loss: 0.84851027  Accuracy: 0.8095238\n",
      "loss: 0.8387536  Accuracy: 0.88095236\n",
      "loss: 0.93688  Accuracy: 0.7619048\n",
      "loss: 1.111524  Accuracy: 0.71428573\n",
      "loss: 1.0388544  Accuracy: 0.72619045\n",
      "loss: 1.051882  Accuracy: 0.72619045\n",
      "loss: 1.0680139  Accuracy: 0.72619045\n",
      "loss: 1.0025316  Accuracy: 0.77380955\n",
      "loss: 0.9609306  Accuracy: 0.75\n",
      "loss: 0.884733  Accuracy: 0.79761904\n",
      "loss: 1.1963948  Accuracy: 0.6904762\n",
      "loss: 0.863232  Accuracy: 0.8095238\n",
      "loss: 0.82253087  Accuracy: 0.8333333\n",
      "loss: 0.9876924  Accuracy: 0.77380955\n",
      "loss: 1.0927489  Accuracy: 0.6547619\n",
      "loss: 0.6898526  Accuracy: 0.9047619\n",
      "loss: 0.671192  Accuracy: 0.86904764\n",
      "loss: 0.6019282  Accuracy: 0.89285713\n",
      "loss: 0.64443004  Accuracy: 0.88095236\n",
      "loss: 0.6119269  Accuracy: 0.9285714\n",
      "loss: 0.5171336  Accuracy: 0.9166667\n",
      "loss: 0.5332574  Accuracy: 0.9404762\n",
      "loss: 0.5819567  Accuracy: 0.9285714\n",
      "loss: 0.48365203  Accuracy: 0.96428573\n",
      "loss: 0.5326176  Accuracy: 0.95238096\n",
      "loss: 0.45661658  Accuracy: 0.97619045\n",
      "loss: 0.47668952  Accuracy: 0.96428573\n",
      "loss: 0.4269425  Accuracy: 0.96428573\n",
      "loss: 0.4140488  Accuracy: 0.97619045\n",
      "loss: 0.39122686  Accuracy: 0.97619045\n",
      "loss: 0.42057645  Accuracy: 0.96428573\n",
      "loss: 0.35908166  Accuracy: 0.96428573\n",
      "loss: 0.3485612  Accuracy: 0.97619045\n",
      "loss: 0.33598748  Accuracy: 0.97619045\n",
      "loss: 0.37500432  Accuracy: 0.96428573\n",
      "loss: 0.36084247  Accuracy: 0.97619045\n",
      "loss: 0.3469672  Accuracy: 0.95238096\n",
      "loss: 0.33891243  Accuracy: 0.97619045\n",
      "loss: 0.3524465  Accuracy: 0.97619045\n",
      "loss: 0.9495099  Accuracy: 0.72619045\n",
      "loss: 0.67261714  Accuracy: 0.8452381\n",
      "loss: 0.5432226  Accuracy: 0.89285713\n",
      "loss: 0.5598758  Accuracy: 0.9404762\n",
      "loss: 0.4122494  Accuracy: 0.9166667\n",
      "loss: 0.3641602  Accuracy: 0.95238096\n",
      "loss: 0.32176653  Accuracy: 0.97619045\n",
      "loss: 0.31418467  Accuracy: 0.9880952\n",
      "loss: 0.32966956  Accuracy: 0.9880952\n",
      "loss: 0.29114807  Accuracy: 0.9880952\n",
      "loss: 0.26609445  Accuracy: 0.9880952\n",
      "loss: 0.2789168  Accuracy: 0.9880952\n",
      "loss: 0.27971357  Accuracy: 0.9880952\n",
      "loss: 0.3572722  Accuracy: 0.96428573\n",
      "loss: 0.3030658  Accuracy: 0.97619045\n",
      "loss: 0.31825858  Accuracy: 0.97619045\n",
      "loss: 0.34414232  Accuracy: 0.97619045\n",
      "loss: 0.31239372  Accuracy: 0.9404762\n",
      "loss: 0.3135384  Accuracy: 0.9880952\n",
      "loss: 0.2461863  Accuracy: 0.9880952\n",
      "loss: 0.29659244  Accuracy: 0.95238096\n",
      "loss: 0.2372708  Accuracy: 0.9880952\n",
      "loss: 0.23709433  Accuracy: 0.9880952\n",
      "loss: 0.20055138  Accuracy: 0.9880952\n",
      "loss: 0.21772137  Accuracy: 0.9880952\n",
      "loss: 0.22625887  Accuracy: 0.9880952\n",
      "loss: 0.20863311  Accuracy: 1.0\n",
      "loss: 0.19920751  Accuracy: 0.9880952\n",
      "loss: 0.19262545  Accuracy: 1.0\n",
      "loss: 0.17139462  Accuracy: 1.0\n",
      "loss: 0.20633233  Accuracy: 0.9880952\n",
      "loss: 0.2395623  Accuracy: 0.9880952\n",
      "loss: 0.26331475  Accuracy: 0.95238096\n",
      "loss: 0.2431978  Accuracy: 0.96428573\n",
      "loss: 0.17921074  Accuracy: 1.0\n",
      "loss: 0.17803879  Accuracy: 0.9880952\n",
      "loss: 0.1953343  Accuracy: 0.9880952\n",
      "loss: 0.18190803  Accuracy: 1.0\n",
      "loss: 0.21966197  Accuracy: 0.97619045\n",
      "loss: 0.17249875  Accuracy: 1.0\n",
      "loss: 0.15472144  Accuracy: 1.0\n",
      "loss: 0.1517001  Accuracy: 1.0\n",
      "loss: 0.18636735  Accuracy: 1.0\n",
      "loss: 0.15675822  Accuracy: 1.0\n",
      "loss: 0.141596  Accuracy: 1.0\n",
      "loss: 0.16899101  Accuracy: 0.9880952\n",
      "loss: 0.14745863  Accuracy: 1.0\n",
      "loss: 0.13556139  Accuracy: 1.0\n",
      "loss: 0.16490147  Accuracy: 1.0\n",
      "loss: 0.12483324  Accuracy: 1.0\n",
      "loss: 0.12354974  Accuracy: 1.0\n",
      "loss: 0.24887714  Accuracy: 0.97619045\n",
      "loss: 0.2586407  Accuracy: 0.96428573\n",
      "loss: 0.30840668  Accuracy: 0.9285714\n",
      "loss: 0.5713879  Accuracy: 0.85714287\n",
      "loss: 0.63654876  Accuracy: 0.8452381\n",
      "loss: 0.6607184  Accuracy: 0.8095238\n",
      "loss: 0.4521123  Accuracy: 0.88095236\n",
      "loss: 0.32913366  Accuracy: 0.97619045\n",
      "loss: 0.21532743  Accuracy: 0.9880952\n",
      "loss: 0.18495534  Accuracy: 0.9880952\n",
      "loss: 0.13036276  Accuracy: 1.0\n",
      "loss: 0.15334867  Accuracy: 1.0\n",
      "loss: 0.15690365  Accuracy: 0.9880952\n",
      "loss: 0.1282494  Accuracy: 1.0\n",
      "loss: 0.10867541  Accuracy: 1.0\n",
      "loss: 0.13017693  Accuracy: 1.0\n",
      "loss: 0.12169317  Accuracy: 1.0\n",
      "loss: 0.12587994  Accuracy: 1.0\n",
      "loss: 0.09989164  Accuracy: 1.0\n",
      "loss: 0.11295523  Accuracy: 1.0\n",
      "loss: 0.12789844  Accuracy: 1.0\n",
      "loss: 0.11963996  Accuracy: 1.0\n",
      "loss: 0.13414943  Accuracy: 0.9880952\n",
      "loss: 0.11372687  Accuracy: 0.9880952\n",
      "loss: 0.10222997  Accuracy: 1.0\n",
      "loss: 0.11455595  Accuracy: 1.0\n",
      "loss: 0.11765712  Accuracy: 0.9880952\n",
      "loss: 0.19906539  Accuracy: 0.97619045\n",
      "loss: 0.10982162  Accuracy: 1.0\n",
      "loss: 0.09178192  Accuracy: 1.0\n",
      "loss: 0.10791656  Accuracy: 1.0\n",
      "loss: 0.10083634  Accuracy: 0.9880952\n",
      "loss: 0.08935896  Accuracy: 1.0\n",
      "loss: 0.06366564  Accuracy: 1.0\n",
      "loss: 0.054067656  Accuracy: 1.0\n",
      "loss: 0.053963166  Accuracy: 1.0\n",
      "loss: 0.045326795  Accuracy: 1.0\n",
      "loss: 0.041051395  Accuracy: 1.0\n",
      "loss: 0.04054099  Accuracy: 1.0\n",
      "loss: 0.038016006  Accuracy: 1.0\n",
      "loss: 0.038508054  Accuracy: 1.0\n",
      "loss: 0.07898627  Accuracy: 1.0\n",
      "loss: 0.06842683  Accuracy: 1.0\n",
      "loss: 0.17299727  Accuracy: 0.96428573\n",
      "loss: 0.49251288  Accuracy: 0.88095236\n",
      "loss: 1.206034  Accuracy: 0.64285713\n",
      "loss: 1.7883769  Accuracy: 0.5119048\n",
      "loss: 2.1088133  Accuracy: 0.42857143\n",
      "loss: 1.4702505  Accuracy: 0.5595238\n",
      "loss: 1.3297195  Accuracy: 0.5952381\n",
      "loss: 0.8555704  Accuracy: 0.7619048\n",
      "loss: 0.61272115  Accuracy: 0.8333333\n",
      "loss: 0.49921235  Accuracy: 0.88095236\n",
      "loss: 0.34733123  Accuracy: 0.9285714\n",
      "loss: 0.27801427  Accuracy: 0.9404762\n",
      "loss: 0.25944012  Accuracy: 0.97619045\n",
      "loss: 0.14800018  Accuracy: 0.9880952\n",
      "loss: 0.13113964  Accuracy: 1.0\n",
      "loss: 0.1278157  Accuracy: 1.0\n",
      "loss: 0.10216529  Accuracy: 0.9880952\n",
      "loss: 0.20596227  Accuracy: 0.9880952\n",
      "loss: 0.1233814  Accuracy: 0.9880952\n",
      "loss: 0.092243865  Accuracy: 1.0\n",
      "loss: 0.069561705  Accuracy: 1.0\n",
      "loss: 0.06611675  Accuracy: 1.0\n",
      "loss: 0.05996352  Accuracy: 1.0\n",
      "loss: 0.0575764  Accuracy: 1.0\n",
      "loss: 0.055486996  Accuracy: 1.0\n",
      "loss: 0.051138062  Accuracy: 1.0\n",
      "loss: 0.050490573  Accuracy: 1.0\n",
      "loss: 0.046976347  Accuracy: 1.0\n",
      "loss: 0.045033023  Accuracy: 1.0\n",
      "loss: 0.04317526  Accuracy: 1.0\n",
      "loss: 0.041417684  Accuracy: 1.0\n",
      "loss: 0.03982142  Accuracy: 1.0\n",
      "loss: 0.03793954  Accuracy: 1.0\n",
      "loss: 0.03675476  Accuracy: 1.0\n",
      "loss: 0.03563432  Accuracy: 1.0\n",
      "loss: 0.034628622  Accuracy: 1.0\n",
      "loss: 0.03359155  Accuracy: 1.0\n",
      "loss: 0.032795686  Accuracy: 1.0\n",
      "loss: 0.031555764  Accuracy: 1.0\n",
      "loss: 0.030939111  Accuracy: 1.0\n",
      "loss: 0.030111628  Accuracy: 1.0\n",
      "loss: 0.029390736  Accuracy: 1.0\n",
      "loss: 0.02845182  Accuracy: 1.0\n",
      "loss: 0.027926289  Accuracy: 1.0\n",
      "loss: 0.027238097  Accuracy: 1.0\n",
      "loss: 0.026654342  Accuracy: 1.0\n",
      "loss: 0.026079785  Accuracy: 1.0\n",
      "loss: 0.02601569  Accuracy: 1.0\n",
      "loss: 0.024892336  Accuracy: 1.0\n",
      "loss: 0.02436672  Accuracy: 1.0\n",
      "loss: 0.023921978  Accuracy: 1.0\n",
      "loss: 0.023898372  Accuracy: 1.0\n",
      "loss: 0.023625085  Accuracy: 1.0\n",
      "loss: 0.025535373  Accuracy: 1.0\n",
      "loss: 0.022410208  Accuracy: 1.0\n",
      "loss: 0.021483168  Accuracy: 1.0\n",
      "loss: 0.021054551  Accuracy: 1.0\n",
      "loss: 0.020462362  Accuracy: 1.0\n",
      "loss: 0.020104712  Accuracy: 1.0\n",
      "loss: 0.019682454  Accuracy: 1.0\n",
      "loss: 0.019653663  Accuracy: 1.0\n",
      "loss: 0.019198705  Accuracy: 1.0\n",
      "loss: 0.019983465  Accuracy: 1.0\n",
      "loss: 0.01939648  Accuracy: 1.0\n",
      "loss: 0.018937072  Accuracy: 1.0\n",
      "loss: 0.017800063  Accuracy: 1.0\n",
      "loss: 0.017222723  Accuracy: 1.0\n",
      "loss: 0.030130398  Accuracy: 1.0\n",
      "loss: 0.875435  Accuracy: 0.77380955\n",
      "loss: 4.1017494  Accuracy: 0.15476191\n",
      "loss: 4.735955  Accuracy: 0.16666667\n",
      "loss: 7.5453405  Accuracy: 0.035714287\n",
      "loss: 8.962376  Accuracy: 0.011904762\n",
      "loss: 7.1135445  Accuracy: 0.011904762\n",
      "loss: 6.872161  Accuracy: 0.035714287\n",
      "loss: 7.0277796  Accuracy: 0.0\n",
      "loss: 6.5768695  Accuracy: 0.035714287\n",
      "loss: 5.8298335  Accuracy: 0.011904762\n",
      "loss: 6.145784  Accuracy: 0.083333336\n",
      "loss: 6.3496485  Accuracy: 0.035714287\n",
      "loss: 6.1352806  Accuracy: 0.05952381\n",
      "loss: 7.692632  Accuracy: 0.023809524\n",
      "loss: 6.2770147  Accuracy: 0.035714287\n",
      "loss: 9.242187  Accuracy: 0.011904762\n"
     ]
    }
   ],
   "source": [
    "\n",
    "epochs =500\n",
    "batch_size=100\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "#t0,t1, t2=sess.run([outputs,logits, prob], feed_dict={X:x_train, Y:y_train})\n",
    "for i in range(epochs):\n",
    "  for j in range(0, x_train.shape[0],batch_size):\n",
    "    x_batch = x_train[j:j+batch_size]\n",
    "    y_batch = y_train[j:j+batch_size]\n",
    "    loss_, train_, acc_ = sess.run([loss,train,acc], feed_dict={X:x_batch, Y:y_batch})\n",
    "  print(\"loss:\",loss_,\" Accuracy:\",acc_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P12aQhoxqaFH",
    "outputId": "ca6fc9e1-1d93-498d-f4bf-e7083b768dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"rnn/transpose_1:0\", shape=(?, 30, 200), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fwehtRGJqaFR"
   },
   "outputs": [],
   "source": [
    "def encode_test(txt):\n",
    "  raw_text_words=re.findall(r\"[\\w]+|[.!?;-]\", txt)\n",
    "  if len(raw_text_words) != seq_length:\n",
    "     raw_text_words = [\"!\"]*(seq_length-len(raw_text_words))+raw_text_words\n",
    "  return [word_to_int[word] for word in raw_text_words]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "jzRHC1Qnwh_b",
    "outputId": "3dfef3d8-7f8b-4c0e-e294-49d004f798f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 118, 718, 961, 806, 232]\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "test=\"The rabbit was sitting by\"\n",
    "pattern = encode_test(test)\n",
    "print(pattern)\n",
    "print(len(pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rnLrbJGGqaFV"
   },
   "outputs": [],
   "source": [
    "# # pick a random seed\n",
    "# start = np.random.randint(0, len(dataX)-1)\n",
    "# #start=0\n",
    "# pattern = dataX[start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "594aQuj7qaFe"
   },
   "outputs": [],
   "source": [
    "# print(start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5ZNqWJFSqaFk"
   },
   "outputs": [],
   "source": [
    "# print(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Nq7B_7PqaFt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RiuC5DfXqaFy"
   },
   "outputs": [],
   "source": [
    "# generate text\n",
    "out=\" \"\n",
    "for i in range(500):\n",
    "    x = np.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(n_vocab)\n",
    "    prediction = sess.run(prob,feed_dict={X:x})\n",
    "    #print(prob.shape)\n",
    "    index = np.argmax(prediction)\n",
    "    #print(index)\n",
    "    result = int_to_word[index]\n",
    "    seq_in = [int_to_word[value] for value in pattern]\n",
    "    out=out+ result+ \" \"\n",
    "    #print(result,)\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "54BSmy0VqaF2",
    "outputId": "f625dbfe-723d-4f6f-b07c-302fc40c8905"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " disagree disagree getting if a very of s other a like if came it so right like didn it that came so doesn very a so good things like either had time she a queer if shrill pool white feet out thousand miles like it it key who it but felt if miles good shelves it still it with a Good like if like felt it t find but when afraid wander it it put soon right a it away here knelt too time doors but very they but certain beautifully know right it talking be wander O However had afraid Dinah The inches time earth holding if it it it it it find sure look had it it a out ever out too it it who be all her if out were quite it it own miles and it if had it so it party it girl like find miles look had it time doors but beautifully printed bristling tart t wind it had it if it look it had soon find Oh felt if know a S it idea quite glass for pattering bright like it called it soon pool so was pool time be ME large afraid ought was called four it pool friends swam garden t thought had it who O altogether beautifully Do gave roof one first it O altogether see tried great for were if low it out went WOULD ME but afraid A Not Ma Ada NEAR disagree odd left things with way it it very be red pounds it a but idea if be had sits WOULD mouse doesn for it so not violently things a and away if time things a tea find had it be any Oh wander sadly with garden mouse beautifully A Why bright gave considering with bring low thousand miles look Who all doesn idea sadly for it it with like too look for with bright except was if but Dinah Are S walrus quite useful was it it it such began for thousand it high good mouse it she look t be roast it wind pool with not low seen very find he Mouse shrill pretend had key other it came a printed talking pool way hall out it house were doors it but doth won who like key it printed find like like it it it miles who right miles she if . doesn if if a S had get it friends called doth like like like felt it time like key it had if had it violently who no table if had good if if history it if right ought up ought thing it for like if it was it toast be wander but great this if for felt it it who pool sure finger had it if ma violently talking a any very if hall indeed called it even it a doth thousand time water get it be wander middle up pool find again declare had ought be Oh had idea pool any \n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "isTVlLD9qaGB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uxxr23zPqaGH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "rnn text gen.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
